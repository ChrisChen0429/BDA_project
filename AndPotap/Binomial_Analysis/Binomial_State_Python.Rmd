---
title: "Poisson Regression"
author: "Andres Potapczynski (ap3635)"
output: pdf_document
---

```{r Imports, include=FALSE}
library(rstan)
library(tidyverse)
library(ggplot2)
library(arm)
library(bayesplot)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
knitr::opts_chunk$set(echo = TRUE)
```

```{r Files, include=FALSE}
file <-  '../DBs/city_st.txt'
# file_model <- './Models/binomial_v01.stan'
# file_model <- './Models/binomial_cauchy.stan'
file_model <- './Models/binomial_state_v01.stan'
# file_model <- './Models/binomial_state_v04.stan'
SEED = 1234
# SEED_TRAIN = 81989843
SEED_TRAIN = 42
CHAINS = 8
ITER = 2000
pct_train = 0.8
pct = 1
# pct = 0.1
# pct = 0.01
comp_sm <- stan_model(file_model)
```

```{r Load the data, include=FALSE}
data <- read_delim(file = file, delim = '|')

# Sample the data
set.seed(seed = SEED)
sample_size = round(pct * nrow(data))
sample <- sample(x = nrow(data), size = sample_size, replace = F)
data = data[sample, ]

## Selecting the relevant columns for the analysis
inputs <- data %>% dplyr::select(
  state,
  city,
  client_income,
  # mar_2_inc,
  appraisal_value,
  app_2_inc,
  # asset_market_value,
  mar_2_app,
  # sex_F,
  # age,
  risk_index,
  employed_30,
  condition_U,
  city_n,
  ID_state,
  y)
summary(inputs)
```

```{r Prep data for STAN model}
## Train / Test split
set.seed(seed = SEED_TRAIN)
pct_train = pct_train
sample_size = round(pct_train * nrow(inputs))
sample <- sample(x = nrow(inputs), size = sample_size, replace = F)

## Allocate train
y = inputs$y

inputs_train = inputs[sample, ]
y_train = y[sample]

## Allocate test
inputs_test = inputs[-sample, ]
y_test = y[-sample]

## Inputs for STAN
X_train = inputs_train %>% dplyr::select(-y, -city_n, -ID_state, -city, -state)
X_test = inputs_test %>% dplyr::select(-y, -city_n, -ID_state, -city, -state)
D = ncol(X_train)
N_train = nrow(X_train)
N_test = nrow(X_test)
State_N_train = inputs$city_n[sample]
State_N_test = inputs$city_n[-sample]
State_train = inputs$ID_state[sample]
State_test = inputs$ID_state[-sample]
S = length(unique(data$state))

data_stan_train = list(N_train=N_train,
                       N_test=N_test,
                       State_N_train=State_N_train,
                       State_N_test=State_N_test,
                       S=S,
                       State_train=State_train,
                       State_test=State_test,
                       D=D,
                       X_train=X_train,
                       X_test=X_test,
                       y_train=y_train)
```

```{r Run first STAN model, include=FALSE}
sm.logistic_v01 = sampling(comp_sm, data=data_stan_train, iter=ITER, chains=CHAINS)
```

```{r Print resutls of logistic regression, echo=FALSE}
print(sm.logistic_v01,
      pars = c('alpha', 'beta'),
      digits = 2, 
      probs = c(0.025, 0.5, 0.975))
```

```{r Extract to evaluate}
sims <- rstan::extract(sm.logistic_v01)
alpha_median <- median(sims$alpha)
beta_median <- apply(X = sims$beta, MARGIN = 2, FUN = median)
y_hat <- apply(X = sims$yrep_test, MARGIN = 2, FUN = mean)
```

```{r Compute test accuracy}
## Baseline
y_hat_baseline <- rep(0, times = length(y_test))

RMSE_baseline = sqrt(mean((y_hat_baseline - y_test) ** 2))
RMSE = sqrt(mean((y_hat - y_test) ** 2))

## Prints
cat('\nBaseline RMSE: ', RMSE_baseline)
cat('\nLogistic RMSE: ', RMSE)
```

```{r Predict at the state level}
test_df = data.frame(ID_state = inputs$ID_state[-sample],
                        state = inputs$state[-sample],
                        y_test = y_test,
                        y_hat = y_hat)
test_df <- test_df %>% 
  group_by(state) %>% 
  summarize(y_sum_test = sum(y_test),
            y_sum_hat = sum(y_hat)) %>% 
  arrange(desc(y_sum_test)) %>% 
  ungroup()

accuracy_baseline = mean(abs(test_df$y_sum_test) ** 2)
accuracy = mean(abs(test_df$y_sum_hat - test_df$y_sum_test) ** 2)

cat('\nBaseline MSE: ', accuracy_baseline)
cat('\nLogistic MSE: ', accuracy)
```
